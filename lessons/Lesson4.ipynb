{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 4 Overview\n",
    "\n",
    "1. Numpy\n",
    "2. Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's load today's lesson!\n",
    "\n",
    "### Open Azure Notebooks library \n",
    "\n",
    "Go to https://notebooks.azure.com -> Sign in if needed -> Select **python-intro**\n",
    "\n",
    "### Update lesson file to latest version\n",
    "\n",
    "Select **New** -> **From URL** -> input https://raw.githubusercontent.com/kelvnt/python-intro/master/lessons/Lesson4.ipynb (URL is available in **Lesson4.ipynb**) -> Click outside input then select **Upload** (overwrite if needed)\n",
    "\n",
    "### Open Jupyter lab\n",
    "\n",
    "From your browser's bookmark or **Run** -> Change browser URL path from **/nb/tree** to **/nb/lab**\n",
    "\n",
    "Select **Lesson4.ipynb**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy\n",
    "\n",
    "NumPy, which stands for Numerical Python, is a library consisting of multidimensional array objects and a collection of routines for processing those arrays. One can perform mathematical and logical operations on arrays more efficiently and effortlessly. \n",
    "\n",
    "**How you import numpy package to your python program:**\n",
    "```python \n",
    "import numpy as np```\n",
    "#### Numpy Arrays:\n",
    "\n",
    "Numpy array is another datatype of python language like the list. Numpy arrays can be created using python list objects.\n",
    "\n",
    "```python \n",
    "np.array(listObject)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "py_list = [1, 3, 10, 50]\n",
    "np_list = np.array(py_list)\n",
    "print(np_list)\n",
    "print(py_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and Numpy assumes values in the array to a single type like booleans, int etc. Trying to create a numpy array with different types, will result in converting all the values to a single type. like the string in below case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "py_list = [1, 'alice', True] \n",
    "np_list = np.array(py_list)  # Numpy arrays contain only one type\n",
    "print(np_list)               # outputs: ['1' 'alice' 'True']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is so special about Numpy arrays ?**\n",
    "\n",
    "Suppose, you have the list of heights and weights of family members(as below) and asked to calculate the BMI of each. By using lists, one has to iterate each of it and which would be inefficient and tiresome to write.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BMI formula is weight/height ** 2\n",
    "\n",
    "heights = [1.73, 1.68, 1.71, 1.89, 1.79]\n",
    "weights = [65.4, 59.2, 63.6, 88.4, 68.7]\n",
    "\n",
    "# find BMI\n",
    "\n",
    "np_heights = np.array(heights)\n",
    "np_weights = np.array(weights)\n",
    "\n",
    "bmi = np_weights / np_heights ** 2\n",
    "\n",
    "print(bmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_heights.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in range(0,len(heights)):\n",
    "    bmi = weights[i]/heights[i]**2\n",
    "    result.append(bmi)\n",
    "    \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's practice with numpy array operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "no_of_seats_per_class = [100, 80, 60, 90]  # list of seats available per class\n",
    "no_of_students_per_class = [82, 34, 49, 88]  # list of students attended per class\n",
    "\n",
    "# find no. of seats vacant per class using numpy array operations\n",
    "# START HERE\n",
    "num_seats = np.array(no_of_seats_per_class)\n",
    "num_students = np.array(no_of_students_per_class)\n",
    "print(num_seats-num_students)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Yes, Numpy makes list operations less expensive and more efficient.** \n",
    "\n",
    "Keep in mind, the same applies for arthematic operators too. For example, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_list = [1, 2, 3]\n",
    "print(\"sum of lists:\", py_list + py_list)   # Results in a new list of 6 elements\n",
    "\n",
    "np_list = np.array(py_list)\n",
    "print(\"sum of np arrays:\", np_list + np_list)  # Results in a array of 3 elements which are the sum of elements of the same index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numpy Subsetting \n",
    "\n",
    "\n",
    "**slicing** \n",
    "\n",
    "\n",
    "Basic slicing is an extension of Python's basic concept of slicing to n dimensions. A Python slice object is constructed by giving a **start**, **stop**, and **step** parameters to the **built-in slice function**. This slice object is passed to the array to extract a part of an array.\n",
    "\n",
    "```python \n",
    "sliceObject = slice(start, stop, step)\n",
    "\n",
    "arrayObject[sliceObject]```\n",
    "\n",
    "alternatively, we can use the slicing parameters seperated by colons.\n",
    "\n",
    "```python \n",
    "arrayObject[start:stop:step] ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrayObject = np.arange(1, 20)  # arange method will generate values within the interval. syntax arange(start,stop,step)\n",
    "print(\"Original array:\", arrayObject)\n",
    "sliceObject = slice(2, 10, 4)\n",
    "\n",
    "sliceArray = arrayObject[sliceObject]\n",
    "print(\"Using slice Object: \", sliceArray)\n",
    "\n",
    "paramArray = arrayObject[2:10:4]\n",
    "print(\"Using slice parameters: \", paramArray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Using array of booleans**\n",
    "\n",
    "Using a conditional statment with square brackets results of np_array results in array of booleans for respective indices and one can filter the array using this result as below.\n",
    "```python\n",
    "    booleanArray = conditional operation on arrayObject\n",
    "    filteredObject = arrayObject[booleanArray]```\n",
    "\n",
    "Here, we are creating a new array from the result of data comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "arrayObject = np.arange(0, 100, 10)\n",
    "print(\"arrayObject:\", arrayObject)\n",
    "\n",
    "booleanArray = arrayObject > 30  # this conditional statement produces the array of booleans\n",
    "print(\"booleanArray:\", booleanArray)\n",
    "\n",
    "filteredObject = arrayObject[booleanArray]\n",
    "print(\"filteredObject:\", filteredObject)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's practice with numpy array of booleans:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "list_of_class = [\"Politics\", \"Engineering\", \"Biology\", \"Maths\"]\n",
    "no_of_seats_per_class = [100, 80, 60, 90]  # list of seats available per class\n",
    "no_of_students_per_class = [82, 80, 49, 90]  # list of students attended per class\n",
    "\n",
    "# print class names with full attendance using numpy array operations and array of booleans:\n",
    "# START HERE\n",
    "a = np.array(list_of_class)\n",
    "b = np.array(no_of_seats_per_class)\n",
    "c = np.array(no_of_students_per_class)\n",
    "\n",
    "booleanArray = b == c\n",
    "print(a[booleanArray])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numpy library\n",
    "\n",
    "**Commonly used methods** \n",
    "\n",
    "**arrayObject.shape**\n",
    "\n",
    "Returns the tuple of array dimensions\n",
    "\n",
    "```python \n",
    "arrayObject.shape\n",
    "\n",
    "print(np.array([[8,9],[9,2]]).shape) #Prints: (2, 2)```\n",
    "\n",
    "**np.zeros**\n",
    "\n",
    "Create an array of all zeros\n",
    "   \n",
    "   ```python\n",
    "   np.zeros(shape, dtype, order)```\n",
    "\n",
    "**np.ones**\n",
    "\n",
    "Create an array of all ones\n",
    "   \n",
    "   ```python\n",
    "   np.ones(shape, dtype, order)```\n",
    "\n",
    "**np.full**\n",
    "\n",
    "Create an array of all the same value\n",
    "   \n",
    "   ```python\n",
    "   np.full(shape, fill_value, dtype, order)```\n",
    "\n",
    "**np.eye**\n",
    "\n",
    "Return a 2-D array with ones on the diagonal and zeros elsewhere.\n",
    "   \n",
    "   ```python\n",
    "   np.eye(n_rows, n_columns, diagonal_index, dtype, order)```\n",
    "\n",
    "**np.amin() and numpy.amax()**\n",
    "\n",
    "These functions return the minimum and the maximum from the elements in the given array along the specified axis.\n",
    "\n",
    "```python \n",
    "   np.amin(arrayObject)\n",
    "\n",
    "   np.amax(arrayObject)```\n",
    "\n",
    "**np.percentile()**\n",
    "\n",
    "Percentile (or a centile) is a measure used in statistics indicating the value below which a given percentage of observations in a group of observations fall. The function numpy.percentile() takes the following arguments.\n",
    "\n",
    "```python\n",
    "np.percentile(arrayObject, q, axis)```\n",
    "\n",
    ">arrayObject : input array\n",
    ">q    : The percentile to compute must be between 0-100\n",
    ">axis : The axis along which the percentile is to be calculated\n",
    "\n",
    "**np.median()**\n",
    "\n",
    "Median is defined as the value separating the higher half of a data sample from the lower half. The numpy.median() function is used as shown in the following program.\n",
    "\n",
    "```python\n",
    "np.median(arrayObject, axis)```\n",
    "\n",
    "**np.mean()**\n",
    "\n",
    "Arithmetic mean is the sum of elements along an axis divided by the number of elements. The numpy.mean() function returns the arithmetic mean of elements in the array. If the axis is mentioned, it is calculated along it.\n",
    "\n",
    "```python\n",
    "np.mean(arrayObject, axis)```\n",
    "\n",
    "**np.average()**\n",
    "\n",
    "Weighted average is an average resulting from the multiplication of each component by a factor reflecting its importance. The numpy.average() function computes the weighted average of elements in an array according to their respective weight given in another array. The function can have an axis parameter. If the axis is not specified, the array is flattened.\n",
    "\n",
    "Considering an array [1,2,3,4] and corresponding weights [4,3,2,1], the weighted average is calculated by adding the product of the corresponding elements and dividing the sum by the sum of weights.\n",
    "\n",
    "\n",
    "```python \n",
    "weighted_average = (1*4+2*3+3*2+4*1)/(4+3+2+1)\n",
    "np.average(arrayObject, weights)```\n",
    "\n",
    "**Standard Deviation**\n",
    "\n",
    "Standard deviation is the square root of the average of squared deviations from mean. The formula for standard deviation is as follows −\n",
    "\n",
    "```python \n",
    "std = sqrt(mean(abs(x - x.mean())\\*\\*2))\n",
    "np.std(arrayObject, axis)```\n",
    "\n",
    "**Variance**\n",
    "\n",
    "Variance is the average of squared deviations. In other words, the standard deviation is the square root of variance.\n",
    "\n",
    "\n",
    "```python \n",
    "variance = mean(abs(x - x.mean())\\*\\*2)\n",
    "np.var(arrayObject, axis)```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "c = np.zeros((3, 3), np.int)\n",
    "print(\"\\nCalling zeros() with shape(3,3):\\n\", c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.ones((3, 3), np.int)\n",
    "print(\"\\nCalling one() with shape(3,3):\\n\", d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = np.full((3, 3), 9, np.int)\n",
    "print(\"\\nCalling full() with shape(3,3) and fill value 9:\\n\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.eye(3, 3, 0, np.int)\n",
    "print(\"\\nCalling eye():\\n\", f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.array([[30, 40, 70], [80, 20, 10], [50, 90, 60]]) \n",
    "\n",
    "print('\\nOriginal Array:\\n', values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### amin and amax\n",
    "print('\\nApplying amin() function:')\n",
    "print(np.amin(values), '\\n')\n",
    "\n",
    "print('Applying amax() function:') \n",
    "print(np.amax(values), '\\n')\n",
    "\n",
    "print('Applying amax() function with axis = 1:')\n",
    "print(np.amax(values, axis=0), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Percentile\n",
    "print('Applying percentile() function:')\n",
    "print(np.percentile(values, 50), '\\n')\n",
    "\n",
    "print('Applying percentile() function along axis 1:')\n",
    "print(np.percentile(values, 50, axis=1), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Median\n",
    "print('Applying median() function:')\n",
    "print(np.median(values), \"\\n\") \n",
    "\n",
    "print('Applying median() function along axis 0:')\n",
    "print(np.median(values, axis=0), '\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Mean\n",
    "print('Applying mean() function:') \n",
    "print(np.mean(values), '\\n') \n",
    "\n",
    "print('Applying mean() function along axis 0:')\n",
    "print(np.mean(values, axis=0), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Average\n",
    "print('Applying average() function:') \n",
    "print(np.average(values), '\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.average(values)) \n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Standard Deviation\n",
    "print('Applying std() function:') \n",
    "print(np.std(values), '\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Variance\n",
    "print('Applying var() function:') \n",
    "print(np.var(values), '\\n') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below are the ticket fares of the first 10 passengers of each class\n",
    "first_class = [71.2833,53.1,51.8625,26.55,35.5,263,27.7208,146.5208,82.1708,52]\n",
    "second_class = [30.0708,16,13,26,13,10.5,21,41.5792,26,10.5]\n",
    "third_class = [7.25,7.925,8.05,8.4583,21.075,11.1333,16.7,8.05,31.275,7.8542]\n",
    "\n",
    "# Q1: Find the max fare of first class passengers\n",
    "f = np.array(first_class)\n",
    "s = np.array(second_class)\n",
    "t = np.array(third_class)\n",
    "\n",
    "for i in [f,s,t]:\n",
    "    print(np.amax(i))\n",
    "\n",
    "# dictionary mapping fare class to list of fares\n",
    "ticket_class = {'1st Class' : first_class,\n",
    "                '2nd Class' : second_class,\n",
    "                '3rd Class' : third_class}\n",
    "\n",
    "# Q2: Print the median, 95th percentile and standard deviation for each ticket class in the format below: \n",
    "# 'ticket class`: median = ___, 95th pct = ___, std dev = ___\n",
    "# use of dictionary is up to you\n",
    "# hint 1: convert list to numpy array and apply mean and median functions\n",
    "# hint 2: for a dictionary called dict, dict.keys() will return a list of keys in that dictionary. \n",
    "# In case you'd like to use a for loop..\n",
    "\n",
    "\n",
    "for x in ticket_class.keys():\n",
    "    array = np.array(ticket_class[x])\n",
    "    median = np.median(array)\n",
    "    pct = np.percentile(array, 95)\n",
    "    std = np.std(array)\n",
    "    print(x, \": median =\", median.round(1), \", 95th pct =\", pct.round(2), \", std dev = \", std.round(0))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back to Pandas\n",
    "\n",
    "What *is* Pandas? [Pandas](https://pandas.pydata.org/) is an open source library providing high-performance, easy-to-use data structures and data analysis tools for Python. Though you might have been thinking about adorable black and white pandas, this name was actually derived from the term *\"panel data\"*, an econometrics term for data sets that include observations over multiple time periods for the same individuals.\n",
    "\n",
    "Pandas is often used together with [Numpy](http://www.numpy.org/) and [scikit-learn](http://scikit-learn.org/stable/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's import pandas library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Data structure - Series\n",
    "\n",
    "A Series is a **one-dimensional** array with labeled axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data into series\n",
    "fruits = pd.Series([\"Apple\", \"Banana\", \"Mango\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do a print, you'll see the index of the dataframe on the very first \"column\". You can then access a particular row with this index.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fruits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits[2]    # returns 'Mango'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can pass in index to create your own index\n",
    "fruits = pd.Series([\"Apple\", \"Banana\", \"Mango\"], index=['a', 'b', 'm'])\n",
    "print(fruits)\n",
    "fruits['m']  # returns 'Mango'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do this again, this time as a dictionary\n",
    "fruits = pd.Series({'a': \"Apple\", 'b': \"Banana\", 'm': \"Mango\"})\n",
    "print(fruits)\n",
    "fruits['m']  # returns 'Mango'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Data structure - DataFrame\n",
    "\n",
    "A DataFrame is a **2-dimensional** table with labeled axes. It acts like a dict-like container for Series objects.\n",
    "\n",
    "The easiest way to create it is to pass it into dictionary, with the key as the header and a corresponding list as the data. The list for each key should be of the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's build a DataFrame of fruit inventory across all floors\n",
    "fruit_inventory = {\n",
    "    \"fruit\": [\"Apple\", \"Banana\", \"Mango\"],\n",
    "    \"fruit_count_2F\": [75, 150, 250],\n",
    "    \"fruit_count_6F\": [80, 120, 150],\n",
    "    \"fruit_count_8F\": [50, 100, 200],\n",
    "    \"fruit_count_9F\": [100, 200, 350],    \n",
    "  }\n",
    "df1 = pd.DataFrame(fruit_inventory)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You get a Series if you access a DataFrame's index\n",
    "df1.fruit # you can also use df1[\"fruit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['fruit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a second dataframe\n",
    "fruit_property = {\n",
    "    \"fruit\": [\"Apple\", \"Banana\", \"Mango\", \"Papaya\"],\n",
    "    \"fruit_color\": [\"red\", \"yellow\", \"yellow\", \"orange\"],\n",
    "  }\n",
    "df2 = pd.DataFrame(fruit_property)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left merge DataFrames df1 and df2 using the 'fruit' column as key \n",
    "# This only retains rows which exist in df1\n",
    "print(df1)\n",
    "print(df2)\n",
    "fruit_list1 = df1.merge(df2, on='fruit', how='left')\n",
    "fruit_list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outer merge DataFrames df1 and df2 using the 'fruit' column as key \n",
    "# All rows are kept, and empty values are filled with NaN (Not a Number)\n",
    "\n",
    "fruit_list2 = df1.merge(df2, on=\"fruit\", how=\"outer\")\n",
    "fruit_list2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's replace NaN value in fruit count columns with 0\n",
    "fruit_list2 = fruit_list2.fillna(0)\n",
    "fruit_list2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summing by row in DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's create a column to sum the total fruit count across all floors\n",
    "\n",
    "# data.loc[<row selection>, <column selection>]\n",
    "# In this case, we're applying across all rows for a selected column range\n",
    "# axis=1 means row-wise, while axis=0 means column-wise\n",
    "\n",
    "fruit_list2['fruit_count_total']= fruit_list2.loc[:, 'fruit_count_2F':'fruit_count_9F'].sum(axis=1)\n",
    "fruit_list2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summing by column in DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(fruit_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fruit_list2['fruit_count_total'].sum())\n",
    "\n",
    "# Let's count all the fruits on each floor\n",
    "\n",
    "# First, create a list of column names which include 'F' \n",
    "columns = [column for column in list(fruit_list2) if 'F' in column]\n",
    "\n",
    "# Next, sum within each column for the column names which include 'F'\n",
    "fruit_count_floor_total = fruit_list2[columns].sum()\n",
    "fruit_count_floor_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the average of a particular column\n",
    "fruit_list2['fruit_count_2F'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the average a couple of columns, per row\n",
    "# the default axis in the .mean() is 0. if we change it to 1, it will compute by the row instead of the column\n",
    "\n",
    "fruit_list2['fruit_count_avg']= fruit_list2.loc[:, 'fruit_count_2F':'fruit_count_9F'].mean(axis=1)\n",
    "fruit_list2.sort_values('fruit_count_avg', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sorting rows in DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Great! Now let's sort the fruit count total in descending order\n",
    "fruit_list2.sort_values('fruit_count_total', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort and display in descending order, only fruits with count exceeding 500 \n",
    "\n",
    "fruit_list2[fruit_list2['fruit_count_total']>500].sort_values('fruit_count_total', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting the number of occurences in a particular column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_list2['fruit_color'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving certain records in DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's retrieve rows containing only yellow fruits\n",
    "fruit_list2.loc[fruit_list2['fruit_color'] == \"yellow\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique fruit colors\n",
    "print(fruit_list2['fruit_color'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grouping and summing in DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group fruit count by fruit color\n",
    "fruit_list2.groupby('fruit_color').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding and deleting columns in DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column 'in_stock' based on function applied to column 'fruit_count_total'\n",
    "# 'in_stock' = True only if fruit_count_total > 0\n",
    "# apply lets us apply our own customized function to the data\n",
    "\n",
    "fruit_list2['in_stock'] = fruit_list2['fruit_count_total'].apply(lambda x: True if x > 0 else False)\n",
    "fruit_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's delete 'in_stock' column\n",
    "del fruit_list2['in_stock']\n",
    "fruit_list2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait... What the f*** is lambda??????\n",
    "\n",
    "Lambda is something unique (? I think so!) to Python. It is **simply another way of writing functions** in Python _(WHY THEY MAKE LIFE SO TOUGH?!)_. \n",
    "\n",
    "We generally use lambda functions when we require a nameless function for a short period of time. Let's see.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's say you want to calculate the cube of a number..\n",
    "# Normal function method\n",
    "def cube_normal(number):\n",
    "    return number**3\n",
    "\n",
    "print(cube_normal(4))\n",
    "\n",
    "# Lambda method\n",
    "cube_lambda = lambda number: number**3\n",
    "\n",
    "print(cube_lambda(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to do what we did just now with both methods..\n",
    "# Using a normal function\n",
    "def greater_than_0(x):\n",
    "    if x >0:\n",
    "        out = True\n",
    "    else: out = False\n",
    "    return out\n",
    "\n",
    "fruit_list2['in_stock'] = fruit_list2['fruit_count_total'].apply(greater_than_0)\n",
    "print(fruit_list2['in_stock'])\n",
    "\n",
    "# Using Lambda\n",
    "fruit_list2['in_stock'] = fruit_list2['fruit_count_total'].apply(lambda x: True if x > 0 else False)\n",
    "print(fruit_list2['in_stock'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference is simply that in the first way, you need to define a function prior to doing the task. This function will stay in your workspace until you ever clear it. In the second way, the function is created on the fly, without the need for defining it. As you can see, it's use is really just as a nameless function that we probably only need once.\n",
    "\n",
    "I can't cover everything, but do read more [here](https://pythonconquerstheuniverse.wordpress.com/2011/08/29/lambda_tutorial/)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregating figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sum of total fruit count\n",
    "print(fruit_list2.agg({'fruit_count_total':'sum'}))\n",
    "\n",
    "# Calculate the sum and median of total fruit count\n",
    "print(fruit_list2.agg({'fruit_count_total':['sum','median']}))\n",
    "\n",
    "# Calculate the max minus the min of fruit_count_2F & fruit_count_6F\n",
    "print(fruit_list2.agg({'fruit_count_2F' : lambda x: max(x) - min(x),\n",
    "                      'fruit_count_6F' : lambda x: max(x) - min(x)}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now it's your turn to use Pandas to explore the Titanic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ready? Let's read the Biggest Loser csv data into a dataframe \n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"../data/titanic.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve top records in DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve bottom records in DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# That's better. How about the bottom 3 rows?\n",
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now you have everything you need to code the following by yourselves!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your turn now! Let's print unique ports of embarkation (C = Cherbourg, Q = Queenstown, S = Southampton)\n",
    "df['Embarked'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try retrieving data for passengers who embarked from Southampton\n",
    "df[df[\"Embarked\"] == \"S\"]\n",
    "df.loc[df[\"Embarked\"] == \"S\"]\n",
    "\n",
    "# The above 2 methods gives the same result, but using .loc is more explicit. I can't quite explain this fully,\n",
    "# but would recommend you to use .loc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the difference between `df['Embarked']` & `df.Embarked?`\n",
    "\n",
    "The `.` is only there for convenience, you can access a pre-existing column _(provided the column name is appropriate - does not have \".\", \" \", etc.)_ but you cannot create a new column with this notation, since the column does not exist yet.\n",
    "\n",
    "Also, what's the difference between `df[df.Embarked == \"S\"]` & `df.loc[df.Embarked == \"S\"]`?\n",
    "\n",
    "If you are selecting a single column, a list of columns, or a slice of rows then there is no difference. However, `[]` does not allow you to select a single row, a list of rows or a slice of columns. More importantly, if your selection involves both rows and columns, then assignment becomes problematic. \n",
    "\n",
    "`df[1:3]['A'] = 5`\n",
    "\n",
    "This selects rows 1 and 2, and then selects column 'A' of the returning object and assign value 5 to it. The problem is, the returning object might be a copy (_please think of this as `inplace = True` vs `inplace = False`_) so this may not change the actual DataFrame. This raises SettingWithCopyWarning. The correct way of this assignment is\n",
    "\n",
    "`df.loc[1:3, 'A'] = 5`\n",
    "\n",
    "With `.loc`, you are guaranteed to modify the original DataFrame. It also allows you to slice columns (`df.loc[:, 'C':'F']`), select a single row (`df.loc[5]`), and select a list of rows (`df.loc[[1, 2, 5]]`). \n",
    "\n",
    "Answer from [stackoverflow](https://stackoverflow.com/questions/48409128/what-is-the-difference-between-using-loc-and-using-just-square-brackets-to-filte)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the overall number of males and females on Titanic\n",
    "df['Sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now add a column called \"family_members\" which takes the sum of the number of siblings/spouse & parents/children\n",
    "\n",
    "# Method 1 (simpler..)\n",
    "df['family_members'] = df.SibSp + df.Parch\n",
    "\n",
    "# Method 2 (why u do diz)\n",
    "df['family_members'] = df.loc[:,[\"SibSp\", \"Parch\"]].sum(axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the columns SibSp & Parch\n",
    "\n",
    "# axis = 1 for column wise dropping, inplace to make the change permanent\n",
    "df.drop(['SibSp','Parch'], axis = 1, inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort and display in descending order, passengers with the most family members on the ship\n",
    "df.sort_values('family_members',ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the overall survival rate\n",
    "# hint: use the .agg({}) and write a lambda function on 'Survived'. Take sum()/len() to get the rate\n",
    "\n",
    "# sum(x) returns the sum of the column 'Survived', while len(x) returns the length of the column 'Survived'\n",
    "df.agg({'Survived':lambda x: sum(x)/len(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the survival rate by ticket class\n",
    "\n",
    "df.groupby('Pclass').agg({'Survived':lambda x: sum(x)/len(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the survival rate by ticket class and by sex\n",
    "\n",
    "df.groupby(['Pclass','Sex']).agg({'Survived':lambda x: sum(x)/len(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the median fare by ticket class, for male passengers\n",
    "\n",
    "# Method 1\n",
    "print(df[df['Sex'] == \"male\"].groupby('Pclass')['Fare'].median())\n",
    "\n",
    "# Method 2\n",
    "print(df[df['Sex'] == \"male\"].groupby('Pclass').agg({'Fare':['median', 'sum', 'count']}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the survival rate by port of embarkation, for passengers aged 30 and above\n",
    "\n",
    "df[df['Age'] >= 30].groupby('Embarked').agg({'Survived':lambda x: sum(x)/len(x)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With that, we have come to the end of our very short introduction to Python! \n",
    "## **Better news: NO HW TODAY!**\n",
    "\n",
    "I hope you've learnt a lot from this and find more opportunities to use and practice it! The journey to using Python at work has only just started and we're are only just at the tip of the tip of the iceberg :D\n",
    "\n",
    "Topics to work on in future:\n",
    "- Managing time series data (datetime)\n",
    "- Plotting (matplotlib, seaborn, plotly, bokeh)\n",
    "- Advanced data wrangling (pandas, data.table (coming soon!))\n",
    "- Natural language processing (gensim, nltk)\n",
    "- Machine learning & AI techniques (sci-kit learn, tensorflow, pytorch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
