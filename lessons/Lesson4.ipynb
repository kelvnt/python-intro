{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 4 Overview\n",
    "\n",
    "1. Numpy\n",
    "2. Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's load today's lesson!\n",
    "\n",
    "### Open Azure Notebooks library \n",
    "\n",
    "Go to https://notebooks.azure.com -> Sign in if needed -> Select **python-intro**\n",
    "\n",
    "### Update lesson file to latest version\n",
    "\n",
    "Select **New** -> **From URL** -> input https://raw.githubusercontent.com/kelvnt/python-intro/master/Lesson4.ipynb (URL is available in **Lesson4.ipynb**) -> Click outside input then select **Upload** (overwrite if needed)\n",
    "\n",
    "### Open Jupyter lab\n",
    "\n",
    "From your browser's bookmark or **Run** -> Change browser URL path from **/nb/tree** to **/nb/lab**\n",
    "\n",
    "Select **Lesson4.ipynb**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy\n",
    "\n",
    "NumPy, which stands for Numerical Python, is a library consisting of multidimensional array objects and a collection of routines for processing those arrays. One can perform mathematical and logical operations on arrays more efficiently and effortlessly. \n",
    "\n",
    "**How you import numpy package to your python program:**\n",
    "```python \n",
    "import numpy as np```\n",
    "#### Numpy Arrays:\n",
    "\n",
    "Numpy array is another datatype of python language like the list. Numpy arrays can be created using python list objects.\n",
    "\n",
    "```python \n",
    "np.array(listObject)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "py_list = [1, 3, 10, 50]\n",
    "np_list = np.array(py_list)\n",
    "print(np_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and Numpy assumes values in the array to a single type like booleans, int etc. Trying to create a numpy array with different types, will result in converting all the values to a single type. like the string in below case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "py_list = [1, 'alice', True] \n",
    "np_list = np.array(py_list)  # Numpy arrays contain only one type\n",
    "print(np_list)               # outputs: ['1' 'alice' 'True']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is so special about Numpy arrays ?**\n",
    "\n",
    "Suppose, you have the list of heights and weights of family members(as below) and asked to calculate the BMI of each. By using lists, one has to iterate each of it and which would be inefficient and tiresome to write.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BMI formula is weight/height ** 2\n",
    "\n",
    "heights = [1.73, 1.68, 1.71, 1.89, 1.79]\n",
    "weights = [65.4, 59.2, 63.6, 88.4, 68.7]\n",
    "\n",
    "# find BMI\n",
    "\n",
    "np_heights = np.array(heights)\n",
    "np_weights = np.array(weights)\n",
    "\n",
    "bmi = np_weights / np_heights ** 2\n",
    "\n",
    "print(bmi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's practice with numpy array operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "no_of_seats_per_class = [100, 80, 60, 90]  # list of seats available per class\n",
    "no_of_students_per_class = [82, 34, 49, 88]  # list of students attended per class\n",
    "\n",
    "# find no. of seats vaccant per class using numpy array operations\n",
    "# START HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Yes, Numpy makes list operations less expensive and more efficient.** \n",
    "\n",
    "Keep in mind, the same applies for arthematic operators too. For example, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_list = [1, 2, 3]\n",
    "print(\"sum of lists:\", py_list + py_list)   # Results in a new list of 6 elements\n",
    "\n",
    "np_list = np.array(py_list)\n",
    "print(\"sum of np arrays:\", np_list + np_list)  # Results in a array of 3 elements which are the sum of elements of the same index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numpy Subsetting \n",
    "\n",
    "\n",
    "**slicing** \n",
    "\n",
    "\n",
    "Basic slicing is an extension of Python's basic concept of slicing to n dimensions. A Python slice object is constructed by giving a **start**, **stop**, and **step** parameters to the **built-in slice function**. This slice object is passed to the array to extract a part of an array.\n",
    "\n",
    "```python \n",
    "sliceObject = slice(start, stop, step)\n",
    "\n",
    "arrayObject[sliceObject]```\n",
    "\n",
    "alternatively, we can use the slicing parameters seperated by colons.\n",
    "\n",
    "```python \n",
    "arrayObject[start:stop:step] ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrayObject = np.arange(1, 20)  # arange method will generate values within the interval. syntax arange(start,stop,step)\n",
    "print(\"Original array:\", arrayObject)\n",
    "sliceObject = slice(2, 10, 4)\n",
    "\n",
    "sliceArray = arrayObject[sliceObject]\n",
    "print(\"Using slice Object: \", sliceArray)\n",
    "\n",
    "paramArray = arrayObject[2:10:4]\n",
    "print(\"Using slice parameters: \", paramArray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Using array of booleans**\n",
    "\n",
    "Using a conditional statment with square brackets results of np_array results in array of booleans for respective indices and one can filter the array using this result as below.\n",
    "```python\n",
    "    booleanArray = conditional operation on arrayObject\n",
    "    filteredObject = arrayObject[booleanArray]```\n",
    "\n",
    "Here, we are creating a new array from the result of data comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "arrayObject = np.arange(0, 100, 10)\n",
    "print(\"arrayObject:\", arrayObject)\n",
    "\n",
    "booleanArray = arrayObject > 30  # this conditional statement produces the array of booleans\n",
    "print(\"booleanArray:\", booleanArray)\n",
    "\n",
    "filteredObject = arrayObject[booleanArray]\n",
    "print(\"filteredObject:\", filteredObject)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's practice with numpy array of booleans:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "list_of_class = [\"Politics\", \"Engineering\", \"Biology\", \"Maths\"]\n",
    "no_of_seats_per_class = [100, 80, 60, 90]  # list of seats available per class\n",
    "no_of_students_per_class = [82, 80, 49, 90]  # list of students attended per class\n",
    "\n",
    "# print class names with full attendance using numpy array operations and array of booleans:\n",
    "# START HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numpy library\n",
    "\n",
    "**Commonly used methods** \n",
    "\n",
    "**arrayObject.shape**\n",
    "\n",
    "Returns the tuple of array dimensions\n",
    "\n",
    "```python \n",
    "arrayObject.shape\n",
    "\n",
    "print(np.array([[8,9],[9,2]]).shape) #Prints: (2, 2)```\n",
    "\n",
    "**np.zeros**\n",
    "\n",
    "Create an array of all zeros\n",
    "   \n",
    "   ```python\n",
    "   np.zeros(shape, dtype, order)```\n",
    "\n",
    "**np.ones**\n",
    "\n",
    "Create an array of all ones\n",
    "   \n",
    "   ```python\n",
    "   np.ones(shape, dtype, order)```\n",
    "\n",
    "**np.full**\n",
    "\n",
    "Create an array of all the same value\n",
    "   \n",
    "   ```python\n",
    "   np.full(shape, fill_value, dtype, order)```\n",
    "\n",
    "**np.eye**\n",
    "\n",
    "Return a 2-D array with ones on the diagonal and zeros elsewhere.\n",
    "   \n",
    "   ```python\n",
    "   np.eye(n_rows, n_columns, diagonal_index, dtype, order)```\n",
    "\n",
    "**np.amin() and numpy.amax()**\n",
    "\n",
    "These functions return the minimum and the maximum from the elements in the given array along the specified axis.\n",
    "\n",
    "```python \n",
    "   np.amin(arrayObject)\n",
    "\n",
    "   np.amax(arrayObject)```\n",
    "\n",
    "**np.percentile()**\n",
    "\n",
    "Percentile (or a centile) is a measure used in statistics indicating the value below which a given percentage of observations in a group of observations fall. The function numpy.percentile() takes the following arguments.\n",
    "\n",
    "```python\n",
    "np.percentile(arrayObject, q, axis)```\n",
    "\n",
    ">arrayObject : input array\n",
    ">q    : The percentile to compute must be between 0-100\n",
    ">axis : The axis along which the percentile is to be calculated\n",
    "\n",
    "**np.median()**\n",
    "\n",
    "Median is defined as the value separating the higher half of a data sample from the lower half. The numpy.median() function is used as shown in the following program.\n",
    "\n",
    "```python\n",
    "np.median(arrayObject, axis)```\n",
    "\n",
    "**np.mean()**\n",
    "\n",
    "Arithmetic mean is the sum of elements along an axis divided by the number of elements. The numpy.mean() function returns the arithmetic mean of elements in the array. If the axis is mentioned, it is calculated along it.\n",
    "\n",
    "```python\n",
    "np.mean(arrayObject, axis)```\n",
    "\n",
    "**np.average()**\n",
    "\n",
    "Weighted average is an average resulting from the multiplication of each component by a factor reflecting its importance. The numpy.average() function computes the weighted average of elements in an array according to their respective weight given in another array. The function can have an axis parameter. If the axis is not specified, the array is flattened.\n",
    "\n",
    "Considering an array [1,2,3,4] and corresponding weights [4,3,2,1], the weighted average is calculated by adding the product of the corresponding elements and dividing the sum by the sum of weights.\n",
    "\n",
    "\n",
    "```python \n",
    "weighted_average = (1*4+2*3+3*2+4*1)/(4+3+2+1)\n",
    "np.average(arrayObject, weights)```\n",
    "\n",
    "**Standard Deviation**\n",
    "\n",
    "Standard deviation is the square root of the average of squared deviations from mean. The formula for standard deviation is as follows −\n",
    "\n",
    "```python \n",
    "std = sqrt(mean(abs(x - x.mean())\\*\\*2))\n",
    "np.std(arrayObject, axis)```\n",
    "\n",
    "**Variance**\n",
    "\n",
    "Variance is the average of squared deviations. In other words, the standard deviation is the square root of variance.\n",
    "\n",
    "\n",
    "```python \n",
    "variance = mean(abs(x - x.mean())\\*\\*2)\n",
    "np.var(arrayObject, axis)```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "c = np.zeros((3, 3), np.int)\n",
    "print(\"\\nCalling zeros() with shape(3,3):\\n\", c)\n",
    "\n",
    "d = np.ones((3, 3), np.int)\n",
    "print(\"\\nCalling one() with shape(3,3):\\n\", d)\n",
    "\n",
    "e = np.full((3, 3), 9, np.int)\n",
    "print(\"\\nCalling full() with shape(3,3) and fill value 9:\\n\", e)\n",
    "\n",
    "f = np.eye(3, 3, 0, np.int)\n",
    "print(\"\\nCalling eye():\\n\", f)\n",
    "\n",
    "values = np.array([[30, 40, 70], [80, 20, 10], [50, 90, 60]]) \n",
    "\n",
    "print('\\nOriginal Array:\\n', values)\n",
    "\n",
    "### amin and amax\n",
    "print('\\nApplying amin() function:')\n",
    "print(np.amin(values), '\\n')\n",
    "\n",
    "print('Applying amax() function:') \n",
    "print(np.amax(values), '\\n')\n",
    "\n",
    "print('Applying amax() function with axis = 1:')\n",
    "print(np.amax(values, axis=0), '\\n')\n",
    "\n",
    "### Percentile\n",
    "print('Applying percentile() function:')\n",
    "print(np.percentile(values, 50), '\\n')\n",
    "\n",
    "print('Applying percentile() function along axis 1:')\n",
    "print(np.percentile(values, 50, axis=1), '\\n')\n",
    "\n",
    "### Median\n",
    "print('Applying median() function:')\n",
    "print(np.median(values), \"\\n\") \n",
    "\n",
    "print('Applying median() function along axis 0:')\n",
    "print(np.median(values, axis=0), '\\n') \n",
    "\n",
    "### Mean\n",
    "print('Applying mean() function:') \n",
    "print(np.mean(values), '\\n') \n",
    "\n",
    "print('Applying mean() function along axis 0:')\n",
    "print(np.mean(values, axis=0), '\\n')\n",
    "\n",
    "### Average\n",
    "print('Applying average() function:') \n",
    "print(np.average(values), '\\n') \n",
    "\n",
    "### Standard Deviation\n",
    "print('Applying std() function:') \n",
    "print(np.std(values), '\\n') \n",
    "\n",
    "### Variance\n",
    "print('Applying var() function:') \n",
    "print(np.var(values), '\\n') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenges (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p1_daily_steps = [11980, 10437, 17616, 24586, 16136, 13700, 39812, 9195, 12855, 11309, 23606, 11848, 6120, 6254, 8754, 6469, 8849, 9911, 7709, 534, 13465, 7341, 11230, 7878, 11029, 8790, 9006, 21942]\n",
    "p2_daily_steps = [22935, 13399, 25098, 29581, 26121, 12805, 16073, 15124, 16011, 6198, 10026, 10909, 14468, 4828, 11207, 7133, 14977, 13746, 12267, 9364, 1061, 6075, 11188, 11472, 10150, 13023, 6769, 10165]\n",
    "p3_daily_steps = [16272, 17231, 20595, 17047, 15216, 42590, 10969, 20687, 19170, 12703, 17192, 12865, 10960, 9105, 16019, 12646, 10042, 13353, 16072, 41673, 13425, 11262, 7801, 6666, 5276, 11353, 5344, 6282]\n",
    "p4_daily_steps = [10233, 16120, 12897, 24680, 13060, 20489, 10230, 25565, 10029, 12696, 13938, 9475, 5297, 8573, 9857, 15341, 9482, 11649, 5804, 11080, 6245, 7611, 8401, 5596, 6491, 7637, 7610, 9130]\n",
    "p5_daily_steps = [14126, 14110, 10111, 20440, 21416, 16989, 25371, 21539, 23045, 20043, 20328, 12058, 12004, 3301, 9789, 6671, 7893, 9589, 10459, 5091, 6329, 6784, 6543, 17984, 13588, 11077, 7856, 20897]\n",
    "\n",
    "team = { # a dictionary mapping initial to list of daily steps\n",
    "    'G': p1_daily_steps, \n",
    "    'I': p2_daily_steps, \n",
    "    'P': p3_daily_steps, \n",
    "    'T': p4_daily_steps, \n",
    "    'D': p5_daily_steps\n",
    "}\n",
    "\n",
    "# Print minimum and maximum no. of steps walked by each person in this format: 'G's (minimum, maximum) steps per day are: (534, 39812)'\n",
    "# Hint 1: convert list to numpy array and apply amin and amax functions. \n",
    "# Hint 2: If a dictionary is called dict, dict.keys() will return the list of keys in that dictionary.\n",
    "\n",
    "# Start here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Print the person with heighest average and his total no. of steps\n",
    "# Hint 1: use numpy's average() and sum() functions\n",
    "\n",
    "# Start here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Print the percentage increment between first two days and last two days of each team member\n",
    "# Hint 1: (total_steps_in_first_2_days - total_steps_in_last_2_days)*100/total_steps\n",
    "# Start here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework\n",
    "Solution can be found in Homework/Solutions/Lesson3.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Easy mode\n",
    "daily_steps = [11980, 10437, 17616, 24586, 16136, 13700, 39812, 9195, 12855, 11309, 23606, 11848, 6120, 6254, 8754, 6469, 8849, 9911, 7709, 534, 13465, 7341, 11230, 7878, 11029, 8790, 9006, 21942]\n",
    "\n",
    "# Find the total number of steps completed by this participant\n",
    "\n",
    "# Start here\n",
    "\n",
    "\n",
    "\n",
    "# Find the average daily steps of this participant. Hint: len(list) will return the number of items inside the list (the length of the list)\n",
    "\n",
    "# Start here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenging mode\n",
    "p1_daily_steps = [11980, 10437, 17616, 24586, 16136, 13700, 39812, 9195, 12855, 11309, 23606, 11848, 6120, 6254, 8754, 6469, 8849, 9911, 7709, 534, 13465, 7341, 11230, 7878, 11029, 8790, 9006, 21942]\n",
    "p2_daily_steps = [22935, 13399, 25098, 29581, 26121, 12805, 16073, 15124, 16011, 6198, 10026, 10909, 14468, 4828, 11207, 7133, 14977, 13746, 12267, 9364, 1061, 6075, 11188, 11472, 10150, 13023, 6769, 10165]\n",
    "p3_daily_steps = [16272, 17231, 20595, 17047, 15216, 42590, 10969, 20687, 19170, 12703, 17192, 12865, 10960, 9105, 16019, 12646, 10042, 13353, 16072, 41673, 13425, 11262, 7801, 6666, 5276, 11353, 5344, 6282]\n",
    "p4_daily_steps = [10233, 16120, 12897, 24680, 13060, 20489, 10230, 25565, 10029, 12696, 13938, 9475, 5297, 8573, 9857, 15341, 9482, 11649, 5804, 11080, 6245, 7611, 8401, 5596, 6491, 7637, 7610, 9130]\n",
    "p5_daily_steps = [14126, 14110, 10111, 20440, 21416, 16989, 25371, 21539, 23045, 20043, 20328, 12058, 12004, 3301, 9789, 6671, 7893, 9589, 10459, 5091, 6329, 6784, 6543, 17984, 13588, 11077, 7856, 20897]\n",
    "\n",
    "team = { # a dictionary mapping initial to list of daily steps\n",
    "    'G': p1_daily_steps, \n",
    "    'I': p2_daily_steps, \n",
    "    'P': p3_daily_steps, \n",
    "    'T': p4_daily_steps, \n",
    "    'D': p5_daily_steps\n",
    "}\n",
    "\n",
    "# Print the total steps of each person in this format: 'Total steps of G is 100000000'\n",
    "# Hint 1: create a function to get total steps per person. \n",
    "# Hint 2: If a dictionary is called dict, dict.keys() will return the list of keys in that dictionary.\n",
    "\n",
    "# Start here\n",
    "\n",
    "\n",
    "\n",
    "# Print the total steps of the team\n",
    "\n",
    "# Start here\n",
    "\n",
    "\n",
    "\n",
    "# Print the initial of the person with total steps of more than 400k\n",
    "\n",
    "# Start here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's talk about Pandas\n",
    "\n",
    "What *is* Pandas? [Pandas](https://pandas.pydata.org/) is an open source library providing high-performance, easy-to-use data structures and data analysis tools for Python. Though you might have been thinking about adorable black and white pandas, this name was actually derived from the term *\"panel data\"*, an econometrics term for data sets that include observations over multiple time periods for the same individuals.\n",
    "\n",
    "Pandas is often used together with [Numpy](http://www.numpy.org/) and [scikit-learn](http://scikit-learn.org/stable/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's import pandas library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Data structure - Series\n",
    "\n",
    "A Series is a **one-dimensional** array with labeled axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data into series where index starts from 0\n",
    "fruits = pd.Series([\"Apple\", \"Banana\", \"Mango\"])\n",
    "fruits[2]    # returns 'Mango'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can pass in index to create your own index\n",
    "fruits = pd.Series([\"Apple\", \"Banana\", \"Mango\"], index=['a', 'b', 'm'])\n",
    "fruits['m']  # returns 'Mango'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do this again, this time as a dictionary\n",
    "fruits = pd.Series({'a': \"Apple\", 'b': \"Banana\", 'm': \"Mango\"})\n",
    "fruits['m']  # returns 'Mango'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Data structure - DataFrame\n",
    "\n",
    "A DataFrame is a **2-dimensional** table with labeled axes. It acts like a dict-like container for Series objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's build a DataFrame of fruit inventory across all floors\n",
    "fruit_inventory = {\n",
    "    \"fruit\": [\"Apple\", \"Banana\", \"Mango\"],\n",
    "    \"fruit_count_2F\": [75, 150, 250],\n",
    "    \"fruit_count_6F\": [80, 120, 150],\n",
    "    \"fruit_count_8F\": [50, 100, 200],\n",
    "    \"fruit_count_9F\": [100, 200, 350],    \n",
    "  }\n",
    "df1 = pd.DataFrame(fruit_inventory)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You get a Series if you access a DataFrame's index\n",
    "df1.fruit  # you can also use df1[\"fruit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a second dataframe\n",
    "fruit_property = {\n",
    "    \"fruit\": [\"Apple\", \"Banana\", \"Mango\", \"Papaya\"],\n",
    "    \"fruit_color\": [\"red\", \"yellow\", \"yellow\", \"orange\"],\n",
    "  }\n",
    "df2 = pd.DataFrame(fruit_property)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left merge DataFrames df1 and df2 using the 'fruit' column as key \n",
    "# This only retains rows which exist in df1\n",
    "\n",
    "fruit_list1 = df1.merge(df2, on='fruit', how='left')\n",
    "fruit_list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outer merge DataFrames df1 and df2 using the 'fruit' column as key \n",
    "# All rows are kept, and empty values are filled with NaN (Not a Number)\n",
    "\n",
    "fruit_list2 = df1.merge(df2, on=\"fruit\", how=\"outer\")\n",
    "fruit_list2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing NaN and casting numbers to integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's replace NaN value in fruit count columns with 0\n",
    "fruit_list2 = fruit_list2.fillna(0)\n",
    "\n",
    "# Let's remove the decimal places that appeared in fruit count after merging DataFrames\n",
    "fruit_list2 = fruit_list2.apply(pd.to_numeric, downcast='integer', errors='ignore')\n",
    "\n",
    "fruit_list2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summing by row in DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's create a column to sum the total fruit count across all floors\n",
    "\n",
    "# data.loc[<row selection>, <column selection>]\n",
    "# In this case, we're applying across all rows for a selected column range\n",
    "# axis=1 means row-wise, while axis=0 means column-wise\n",
    "\n",
    "fruit_list2['fruit_count_total']= fruit_list2.loc[:, 'fruit_count_2F':'fruit_count_9F'].sum(axis=1)\n",
    "fruit_list2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summing by column in DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's count all the fruits on each floor\n",
    "\n",
    "# First, create a list of column names which include 'F' \n",
    "columns = [column for column in list(fruit_list2) if 'F' in column]\n",
    "\n",
    "# Next, sum within each column for the column names which include 'F'\n",
    "fruit_count_floor_total = fruit_list2[columns].sum()\n",
    "fruit_count_floor_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's find out the average fruit count for each floor\n",
    "\n",
    "fruit_list2['fruit_count_avg']= fruit_list2.loc[:, 'fruit_count_2F':'fruit_count_9F'].mean(axis=1).round(0)\n",
    "fruit_list2.sort_values('fruit_count_avg', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sorting rows in DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Great! Now let's sort the fruit count total in descending order\n",
    "fruit_list2.sort_values('fruit_count_total', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort and display in descending order, only fruits with count exceeding 500 \n",
    "\n",
    "fruit_list2[fruit_list2['fruit_count_total']>500].sort_values('fruit_count_total', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving certain records in DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's retrieve rows containing only yellow fruits\n",
    "fruit_list2.loc[fruit_list2['fruit_color'] == \"yellow\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique fruit colors\n",
    "print(fruit_list2['fruit_color'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grouping and summing in DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group fruit count by fruit color\n",
    "fruit_list2.groupby('fruit_color').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding and deleting columns in DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column 'in_stock' based on function applied to column 'fruit_count_total'\n",
    "# 'in_stock' = True only if fruit_count_total > 0\n",
    "\n",
    "fruit_list2['in_stock'] = fruit_list2['fruit_count_total'].apply(lambda x: True if x > 0 else False)\n",
    "fruit_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's delete 'in_stock' column\n",
    "del fruit_list2['in_stock']\n",
    "fruit_list2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now it's your turn to use Pandas to explore Biggest Loser data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ready? Let's read the Biggest Loser csv data into a dataframe \n",
    "\n",
    "df = pd.read_csv('Biggest Loser 2018.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve top records in DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Too many rows! How can we read the top 5?\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve bottom records in DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# That's better. How about the bottom 3 rows?\n",
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now you have everything you need to code the following by yourselves!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your turn now! Let's print unique team names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Great! Now retrieve data for only team_no 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now add a column called member_tot_steps to store each person's total count across the challenge\n",
    "# sort rows by total steps in descending order; display top 3\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort and display in descending order, individuals who have exceeded 350K steps\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column called member_avg_steps to store average steps for each member across the challenge\n",
    "# sort individuals by average steps in descending order; display top 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum total daily steps for each team into a new DataFrame called team_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In DataFrame team_df, remove a column e.g. team captain\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In DataFrame team_df, add a column called team_tot_steps \n",
    "# This will store total steps for each team for entire challenge\n",
    "# Sort teams by total steps in descending order; display top 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In DataFrame team_df, sort & display in descending order, teams who have exceeded 1 million steps\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
